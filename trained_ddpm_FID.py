# -*- coding: utf-8 -*-
"""Trained_denoisingDiffusionPytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fMUmrvm54fO2uDL_w2iJZw4JrPo_CKd6
"""

from google.colab import drive
drive.mount('/content/drive')

"""# MRI Image Generation and Evaluation Using a Diffusion Model

This notebook demonstrates how to load a trained diffusion model, generate new synthetic MRI images, visualize them, and evaluate their quality using standard metrics.  
The goal is to create realistic MRI images that resemble the original dataset while keeping the process efficient.

### What this workflow covers
- **Loading a pretrained UNet-based diffusion model** used for MRI enhancement or synthesis.  
- **Sampling new MRI images** by letting the model generate images from noise.  
- **Visualizing the generated results** using clean Matplotlib grids.  
- **Inspecting model parameters** to ensure the architecture and weights were restored correctly.  
- **Comparing real vs. generated images** by counting dataset images and preparing inputs.  
- **Evaluating generation quality** using the **FID score**, a widely accepted metric in generative modeling.

### Why this matters
Diffusion models have become one of the most powerful methods for medical image synthesis because they can generate high-fidelity images with realistic anatomical structure and noise patterns.  
This workflow provides a complete pipeline from loading the model to generating images and evaluating them so that researchers can verify model performance and ensure reproducibility.
"""

!pip install denoising_diffusion_pytorch

"""## Loading the Trained Diffusion Model (UNet + Gaussian Diffusion)

This section restores the trained MRI enhancement model from a saved checkpoint and prepares it for inference in Google Colab.

### What the code does
- Rebuilds the **UNet architecture** exactly as it was during training  
  (same `dim`, `dim_mults`, and `flash_attn` settings).  
- Loads the saved weights from `model_checkpoint.pt` stored in Google Drive.  
- Moves the model to the appropriate device — GPU when available, otherwise CPU.  
- Recreates the `GaussianDiffusion` wrapper using the same parameters used during training (image size, timesteps, sampling steps).  
- Confirms that both the UNet and diffusion objects are placed on the correct device.  
- Prints a message once everything is successfully loaded and ready for sampling.

"""

# load the saved model
import torch
from denoising_diffusion_pytorch import Unet, GaussianDiffusion

# Re-define the model architecture (make sure it's the same as the one you trained)
model = Unet(
    dim = 64,
    dim_mults = (1, 2, 4, 8),
    flash_attn = True
)

# Define the path to your saved model checkpoint
saved_model_path = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/model/model_checkpoint.pt'

# Load the saved state dictionary into the model
checkpoint = torch.load(saved_model_path)

# The state_dict is saved directly in this case
model.load_state_dict(checkpoint)

# Move the model to the appropriate device (GPU if available)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Add a check to confirm the model is on the correct device
print(f"Model is on device: {next(model.parameters()).device}")


# Re-define the GaussianDiffusion object with the loaded model
diffusion = GaussianDiffusion(
    model,
    image_size = 128,
    timesteps = 1000,           # number of steps
    sampling_timesteps = 100    # number of sampling timesteps (using ddim for faster inference)
)
diffusion.to(device) # Ensure the diffusion object itself is on the correct device

print("Model loaded successfully!")

"""## Counting Original MRI Images in the Dataset Folder

Before generating or evaluating images, it's useful to check how many real MRI files exist in the dataset directory.  
This ensures all data was uploaded correctly to Google Drive.

### What the code does
- Defines the Google Drive folder where the original MRI images are stored.  
- Filters all files in that directory by valid image extensions (e.g., `.png`, `.jpg`, `.tiff`).  
- Counts how many true image files are present.  
- Prints the total so you can confirm the dataset size before running the diffusion model.


"""

# show how many original images in the folder
import os

folder_path = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain'
image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'] # Add or remove extensions as needed

if os.path.exists(folder_path):
    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and os.path.splitext(f)[1].lower() in image_extensions]
    num_image_files = len(image_files)
    print(f"There are {num_image_files} image files in '{folder_path}'")
else:
    print(f"The folder '{folder_path}' does not exist.")

"""## Exploring Trainable Model Parameters

This step prints out the structure of the UNet by showing every trainable layer, its tensor shape, and a small preview of parameter values.  
It’s useful for confirming that the architecture was rebuilt correctly and that all weights were loaded from the checkpoint.

### What the code does
- Iterates through `model.named_parameters()` to access each layer.  
- Filters only parameters where `requires_grad=True` (the trainable ones).  
- Prints for each layer:
  - **Layer name**
  - **Tensor shape**
  - **First few parameter values**  
- Helps verify:
  - The model matches the training architecture  
  - All weights were loaded properly  
  - No layers are unexpectedly frozen or missing


"""

# Explore the model's parameters
for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"Layer: {name} | Size: {param.size()} | Values : {param.data[:2]}")

"""## Generating New MRI Images Using the Diffusion Model

This section uses the trained diffusion model to create a batch of synthetic MRI images.  
The model samples new images from noise and returns them as PyTorch tensors.

### What the code does
- Calls `diffusion.sample(batch_size=32)` to generate 32 new MRI images.  
- Converts each tensor from **C×H×W** to **H×W×C** format for plotting.  
- Uses Matplotlib to display the results in a **4-column grid**, with rows added automatically.  
- Removes axes and hides empty subplots for cleaner presentation.  
- Uses `plt.tight_layout()` to make the grid spacing neat and readable.

### Purpose
This helps visually inspect the quality of the generated MRIs and check whether the model has learned realistic anatomical structure and texture.


"""

# Generate images
sampled_images = diffusion.sample(batch_size = 32)

# Display the generated images (requires matplotlib)
import matplotlib.pyplot as plt
import math

def show_images(images, cols=4):
    rows = math.ceil(len(images) / cols)
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))
    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration

    for i, img in enumerate(images):
        axes[i].imshow(img.permute(1, 2, 0).cpu().numpy())
        axes[i].axis('off')

    # Hide any unused subplots if the number of images is not a perfect multiple of cols
    for j in range(i + 1, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

show_images(sampled_images, cols=4)

"""## FID Score Evaluation (Fréchet Inception Distance)

This step evaluates how close the generated MRI images are to the real dataset by computing the **FID score**. Lower values mean the synthetic images better match the real distribution. (Scores under **20** indicate high-quality generation, though this usually requires longer training.)

### What the code does
- Converts generated images from tensors (`[-1, 1]`) into proper 8-bit RGB image files.  
- Saves a temporary folder of **generated samples** for comparison.  
- Resizes real MRI images to the same resolution and format expected by the FID model.  
- Ensures real images are 3-channel RGB (required by FID).  
- Computes the FID score between the real and generated folders.  
- Cleans up temporary files afterward.



"""

# calculate FID score. It is great if the score is lower than 20. But we need a long time to train the model
import torch
from pytorch_fid import fid_score
import os
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Assuming 'sampled_images' contains the generated images (PyTorch tensor)
# and the real images are in the folder specified in the trainer

# Convert generated images to the expected format (numpy array, uint8, HxWx3)
# The generated images are likely in the range [-1, 1] and in CxHxW format
generated_images_np = ((sampled_images + 1) * 127.5).clamp(0, 255).permute(0, 2, 3, 1).cpu().numpy().astype('uint8')

# Create temporary directories to save generated and resized real images for FID calculation
temp_gen_dir = './temp_generated_images'
temp_real_dir = './temp_real_images_resized'
os.makedirs(temp_gen_dir, exist_ok=True)
os.makedirs(temp_real_dir, exist_ok=True)


for i, img in enumerate(generated_images_np):
    # Convert grayscale to RGB if needed (FID expects 3 channels)
    if img.shape[2] == 1:
        # Assuming grayscale images are provided as HxWx1 or HxW
        # If HxW, add a channel dimension
        if img.ndim == 2:
            img = img[:, :, np.newaxis]
        img = img.repeat(3, axis=2) # Repeat the single channel 3 times
    plt.imsave(os.path.join(temp_gen_dir, f'gen_img_{i}.png'), img)

# Resize real images to a consistent size and save them
real_image_folder = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain'
image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']

real_image_files = [os.path.join(real_image_folder, f) for f in os.listdir(real_image_folder) if os.path.isfile(os.path.join(real_image_folder, f)) and os.path.splitext(f)[1].lower() in image_extensions]

# Determine a target size (e.g., the size of generated images)
target_size = (generated_images_np.shape[2], generated_images_np.shape[1]) # (width, height)


for i, img_path in enumerate(real_image_files):
    try:
        img = Image.open(img_path)
        # Ensure image has 3 channels
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img_resized = img.resize(target_size)
        img_resized.save(os.path.join(temp_real_dir, f'real_img_{i}.png'))
    except Exception as e:
        print(f"Could not process image {img_path}: {e}")
        continue


# Calculate FID score
# Provide the path to the resized real images folder and the temporary generated images folder
fid_value = fid_score.calculate_fid_given_paths([temp_real_dir, temp_gen_dir],
                                                batch_size=generated_images_np.shape[0],
                                                device='cuda' if torch.cuda.is_available() else 'cpu',
                                                dims=2048)

print(f"FID Score: {fid_value}")

# Clean up the temporary directories
import shutil
shutil.rmtree(temp_gen_dir)
shutil.rmtree(temp_real_dir)