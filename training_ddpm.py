# -*- coding: utf-8 -*-
"""Share_denoisingDMSucc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k0X97cNhFVCGIgQdjQfI09hQjv-YfeAm
"""

from google.colab import drive
drive.mount('/content/drive')

pip install denoising_diffusion_pytorch

from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

model = Unet(
    dim = 64,
    dim_mults = (1, 2, 4, 8),
    flash_attn = True
)

diffusion = GaussianDiffusion(
    model,
    image_size = 128,
    timesteps = 1000,           # number of steps
    sampling_timesteps = 100    # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])
)

trainer = Trainer(
    diffusion,
    '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain', #change to your local drive
    train_batch_size = 32,
    train_lr = 8e-5,
    train_num_steps = 50000,         # total training steps
    gradient_accumulate_every = 2,    # gradient accumulation steps
    ema_decay = 0.995,                # exponential moving average decay
    amp = True,                       # turn on mixed precision
    calculate_fid = False              # whether to calculate fid during training
)

trainer.train()

import torch
import os

# Define the desired save path
save_path = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/model/model_checkpoint.pt'

# Ensure the directory exists
os.makedirs(os.path.dirname(save_path), exist_ok=True)

# Save the model's state dictionary
# Assuming 'model' is your trained Unet model
torch.save(model.state_dict(), save_path)

print(f"Model saved successfully to {save_path}")

# load the saved model
import torch
from denoising_diffusion_pytorch import Unet, GaussianDiffusion

# Re-define the model architecture (make sure it's the same as the one you trained)
model = Unet(
    dim = 64,
    dim_mults = (1, 2, 4, 8),
    flash_attn = True
)

# Define the path to your saved model checkpoint
saved_model_path = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/model/model_checkpoint.pt'

# Load the saved state dictionary into the model
checkpoint = torch.load(saved_model_path)

# The state_dict is saved directly in this case
model.load_state_dict(checkpoint)

# Move the model to the appropriate device (GPU if available)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Add a check to confirm the model is on the correct device
print(f"Model is on device: {next(model.parameters()).device}")


# Re-define the GaussianDiffusion object with the loaded model
diffusion = GaussianDiffusion(
    model,
    image_size = 128,
    timesteps = 1000,           # number of steps
    sampling_timesteps = 100    # number of sampling timesteps (using ddim for faster inference)
)

print("Model loaded successfully!")

# show how many original images in the folder
import os

folder_path = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain'
image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'] # Add or remove extensions as needed

if os.path.exists(folder_path):
    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and os.path.splitext(f)[1].lower() in image_extensions]
    num_image_files = len(image_files)
    print(f"There are {num_image_files} image files in '{folder_path}'")
else:
    print(f"The folder '{folder_path}' does not exist.")

# Explore the model's parameters
for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"Layer: {name} | Size: {param.size()} | Values : {param.data[:2]}")

import matplotlib.pyplot as plt
import math
import torch # Import torch to use torch.cuda.is_available() and .to(device)

# Define device again to make this cell self-contained, if not already in scope
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Ensure the diffusion model itself is on the correct device
diffusion.to(device)

# Generate images
sampled_images = diffusion.sample(batch_size = 16)

# Display the generated images (requires matplotlib)

def show_images(images, cols=4):
    rows = math.ceil(len(images) / cols)
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))
    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration

    for i, img in enumerate(images):
        axes[i].imshow(img.permute(1, 2, 0).cpu().numpy())
        axes[i].axis('off')

    # Hide any unused subplots if the number of images is not a perfect multiple of cols
    for j in range(i + 1, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

show_images(sampled_images, cols=4)

import matplotlib.pyplot as plt
import random
import os
from PIL import Image, ImageEnhance
import numpy as np
import torch

def show_comparisons(generated_images, real_image_folder, num_comparisons=16, brightness_factor=1.0, contrast_factor=1.0):
    """Displays original and generated images side-by-side with optional adjustments."""

    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']
    real_image_files = [os.path.join(real_image_folder, f) for f in os.listdir(real_image_folder) if os.path.isfile(os.path.join(real_image_folder, f)) and os.path.splitext(f)[1].lower() in image_extensions]

    # Ensure we don't request more comparisons than available images
    num_comparisons = min(num_comparisons, len(generated_images), len(real_image_files))

    # Select random indices for comparison
    generated_indices = random.sample(range(len(generated_images)), num_comparisons)
    real_indices = random.sample(range(len(real_image_files)), num_comparisons)

    fig, axes = plt.subplots(num_comparisons, 2, figsize=(8, num_comparisons * 4))

    for i in range(num_comparisons):
        # Display Original Image
        real_img_path = real_image_files[real_indices[i]]
        try:
            real_img = Image.open(real_img_path).convert('RGB')
            axes[i, 0].imshow(real_img)
            axes[i, 0].set_title("Original")
            axes[i, 0].axis('off')
        except Exception as e:
            print(f"Could not load original image {real_img_path}: {e}")
            axes[i, 0].set_title("Error loading original")
            axes[i, 0].axis('off')


        # Display Generated Image
        gen_img_tensor = generated_images[generated_indices[i]]
        # Convert generated image tensor to PIL Image for adjustments
        gen_img_np = ((gen_img_tensor) * 127.5).clamp(0, 128).permute(1, 2, 0).cpu().numpy().astype('uint8')
        gen_img_pil = Image.fromarray(gen_img_np, 'RGB')

        # Apply brightness and contrast adjustments
        enhancer_b = ImageEnhance.Brightness(gen_img_pil)
        img_brightened = enhancer_b.enhance(brightness_factor)
        enhancer_c = ImageEnhance.Contrast(img_brightened)
        img_adjusted = enhancer_c.enhance(contrast_factor)


        axes[i, 1].imshow(img_adjusted)
        axes[i, 1].set_title(f"Generated (B:{brightness_factor}, C:{contrast_factor})")
        axes[i, 1].axis('off')

    plt.tight_layout()
    plt.show()

# Assuming 'sampled_images' contains the generated images and 'trainer.folder' has the path to original images
real_image_folder = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain'
# Example usage with adjusted brightness and contrast
show_comparisons(sampled_images, real_image_folder, num_comparisons=8, brightness_factor=2.0, contrast_factor=2.0)

# Check values of generated images to ensure they are not blank
print("Min value in sampled_images:", sampled_images.min().item())
print("Max value in sampled_images:", sampled_images.max().item())
print("Mean value in sampled_images:", sampled_images.mean().item())

# Display just one image to see if it works
plt.figure(figsize=(4,4))
# Ensure the image is converted from [-1, 1] to [0, 1] for display
img_to_display = (sampled_images[0] + 1) / 2
plt.imshow(img_to_display.permute(1, 2, 0).cpu().numpy())
plt.axis('off')
plt.title("First Generated Image (Normalized for Display)")
plt.show()

# calculate FID score. It is great if the score is lower than 20. But we need a long time to train the model
import torch
from pytorch_fid import fid_score
import os
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Assuming 'sampled_images' contains the generated images (PyTorch tensor)
# and the real images are in the folder specified in the trainer

# Convert generated images to the expected format (numpy array, uint8, HxWx3)
# The generated images are likely in the range [-1, 1] and in CxHxW format
generated_images_np = ((sampled_images + 1) * 127.5).clamp(0, 255).permute(0, 2, 3, 1).cpu().numpy().astype('uint8')

# Create temporary directories to save generated and resized real images for FID calculation
temp_gen_dir = './temp_generated_images'
temp_real_dir = './temp_real_images_resized'
os.makedirs(temp_gen_dir, exist_ok=True)
os.makedirs(temp_real_dir, exist_ok=True)


for i, img in enumerate(generated_images_np):
    # Convert grayscale to RGB if needed (FID expects 3 channels)
    if img.shape[2] == 1:
        # Assuming grayscale images are provided as HxWx1 or HxW
        # If HxW, add a channel dimension
        if img.ndim == 2:
            img = img[:, :, np.newaxis]
        img = img.repeat(3, axis=2) # Repeat the single channel 3 times
    plt.imsave(os.path.join(temp_gen_dir, f'gen_img_{i}.png'), img)

# Resize real images to a consistent size and save them
real_image_folder = '/content/drive/MyDrive/ColabNotebooks/EnhanceMRIdata/brain'
image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']

real_image_files = [os.path.join(real_image_folder, f) for f in os.listdir(real_image_folder) if os.path.isfile(os.path.join(real_image_folder, f)) and os.path.splitext(f)[1].lower() in image_extensions]

# Determine a target size (e.g., the size of generated images)
target_size = (generated_images_np.shape[2], generated_images_np.shape[1]) # (width, height)


for i, img_path in enumerate(real_image_files):
    try:
        img = Image.open(img_path)
        # Ensure image has 3 channels
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img_resized = img.resize(target_size)
        img_resized.save(os.path.join(temp_real_dir, f'real_img_{i}.png'))
    except Exception as e:
        print(f"Could not process image {img_path}: {e}")
        continue


# Calculate FID score
# Provide the path to the resized real images folder and the temporary generated images folder
fid_value = fid_score.calculate_fid_given_paths([temp_real_dir, temp_gen_dir],
                                                batch_size=generated_images_np.shape[0],
                                                device='cuda' if torch.cuda.is_available() else 'cpu',
                                                dims=2048)

print(f"FID Score: {fid_value}")

# Clean up the temporary directories
import shutil
shutil.rmtree(temp_gen_dir)
shutil.rmtree(temp_real_dir)